{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/DSINE-jupyter/blob/main/test.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/DSINE\n",
        "%cd /content/DSINE\n",
        "\n",
        "!pip install geffnet glob2\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/DSINE/resolve/main/dsine.pt -d /content/DSINE/checkpoints -o dsine.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import utils.utils as utils\n",
        "\n",
        "\n",
        "def test_samples(img_path, model, intrins=None, device='cpu'):\n",
        "    # normalize\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        print(img_path)\n",
        "        ext = os.path.splitext(img_path)[1]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = np.array(img).astype(np.float32) / 255.0\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).to(device)\n",
        "        _, _, orig_H, orig_W = img.shape\n",
        "\n",
        "        # zero-pad the input image so that both the width and height are multiples of 32\n",
        "        l, r, t, b = utils.pad_input(orig_H, orig_W)\n",
        "        img = F.pad(img, (l, r, t, b), mode=\"constant\", value=0.0)\n",
        "        img = normalize(img)\n",
        "\n",
        "        intrins_path = img_path.replace(ext, '.txt')\n",
        "        if os.path.exists(intrins_path):\n",
        "            # NOTE: camera intrinsics should be given as a txt file\n",
        "            # it should contain the values of fx, fy, cx, cy\n",
        "            intrins = utils.get_intrins_from_txt(intrins_path, device=device).unsqueeze(0)\n",
        "        else:\n",
        "            # NOTE: if intrins is not given, we just assume that the principal point is at the center\n",
        "            # and that the field-of-view is 60 degrees (feel free to modify this assumption)\n",
        "            intrins = utils.get_intrins_from_fov(new_fov=60.0, H=orig_H, W=orig_W, device=device).unsqueeze(0)\n",
        "\n",
        "        intrins[:, 0, 2] += l\n",
        "        intrins[:, 1, 2] += t\n",
        "\n",
        "        pred_norm = model(img, intrins=intrins)[-1]\n",
        "        pred_norm = pred_norm[:, :, t:t+orig_H, l:l+orig_W]\n",
        "\n",
        "        # save to output folder\n",
        "        # NOTE: by saving the prediction as uint8 png format, you lose a lot of precision\n",
        "        # if you want to use the predicted normals for downstream tasks, we recommend saving them as float32 NPY files\n",
        "        pred_norm_np = pred_norm.cpu().detach().numpy()[0,:,:,:].transpose(1, 2, 0) # (H, W, 3)\n",
        "        pred_norm_np = ((pred_norm_np + 1.0) / 2.0 * 255.0).astype(np.uint8)\n",
        "        im = Image.fromarray(pred_norm_np)\n",
        "        im.save('/content/test.png')\n",
        "    \n",
        "# define model\n",
        "from models.dsine import DSINE\n",
        "device = torch.device('cuda')\n",
        "model = DSINE().to(device)\n",
        "model.pixel_coords = model.pixel_coords.to(device)\n",
        "model = utils.load_checkpoint('/content/DSINE/checkpoints/dsine.pt', model)\n",
        "model.eval()\n",
        "test_samples('/content/DSINE/samples/img/232334_ALI.png', model, intrins=None, device=device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
